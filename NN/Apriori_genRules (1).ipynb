{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yJK0ECjE5vK"
   },
   "source": [
    "### This Notebook is used to understand Aprioiri Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivfAbVvYHrRA"
   },
   "source": [
    "**Following Cell is used to load a test dataset containing 5 records. But You Should use your funcion to load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "    \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "    of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "    _itemSet = set()\n",
    "    localSet = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for transaction in transactionList:\n",
    "            if item.issubset(transaction):\n",
    "                freqSet[item] += 1\n",
    "                localSet[item] += 1\n",
    "\n",
    "    for item, count in localSet.items():\n",
    "        support = float(count) / len(transactionList)\n",
    "\n",
    "        if support >= minSupport:\n",
    "            _itemSet.add(item)\n",
    "\n",
    "    return _itemSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinSet(itemSet, length):\n",
    "    \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "    return set(\n",
    "        [i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))  # Generate 1-itemSets\n",
    "    return itemSet, transactionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while currentLSet != set([]):\n",
    "        largeSet[k - 1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(\n",
    "            currentLSet, transactionList, minSupport, freqSet\n",
    "        )\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item]) / len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item)) for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item) / getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)), confidence))\n",
    "    return toRetItems, toRetRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_results(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    i, r = [], []\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        x = \"item: %s , %.3f\" % (str(item), support)\n",
    "        i.append(x)\n",
    "\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        x = \"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence)\n",
    "        r.append(x)\n",
    "\n",
    "    return i, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFromFile(fname):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    with open(fname, \"rU\") as file_iter:\n",
    "        for line in file_iter:\n",
    "            line = line.strip().rstrip(\",\")  # Remove trailing comma\n",
    "            record = frozenset(line.split(\",\"))\n",
    "            yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('Brooklyn',) , 0.152\n",
      "item: ('HISPANIC',) , 0.164\n",
      "item: ('MBE', 'HISPANIC') , 0.164\n",
      "item: ('MBE', 'WBE') , 0.169\n",
      "item: ('MBE', 'New York') , 0.170\n",
      "item: ('WBE', 'New York') , 0.175\n",
      "item: ('MBE', 'ASIAN') , 0.200\n",
      "item: ('ASIAN',) , 0.202\n",
      "item: ('New York',) , 0.295\n",
      "item: ('NON-MINORITY',) , 0.300\n",
      "item: ('WBE', 'NON-MINORITY') , 0.300\n",
      "item: ('BLACK',) , 0.301\n",
      "item: ('MBE', 'BLACK') , 0.301\n",
      "item: ('WBE',) , 0.477\n",
      "item: ('MBE',) , 0.671\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('New York',) ==> ('MBE',) , 0.578\n",
      "Rule: ('New York',) ==> ('WBE',) , 0.594\n",
      "Rule: ('WBE',) ==> ('NON-MINORITY',) , 0.628\n",
      "Rule: ('ASIAN',) ==> ('MBE',) , 0.990\n",
      "Rule: ('NON-MINORITY',) ==> ('WBE',) , 1.000\n",
      "Rule: ('HISPANIC',) ==> ('MBE',) , 1.000\n",
      "Rule: ('BLACK',) ==> ('MBE',) , 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inFile=dataFromFile('basket.csv')\n",
    "minSupport = 0.15\n",
    "minConfidence = 0.5\n",
    "\n",
    "items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
